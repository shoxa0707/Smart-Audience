{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9667895-4107-43e4-b3f1-62c15e8e57bd",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a19338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, from_numpy, cuda, optim, save, load, unsqueeze\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torchvision import datasets,transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from models import Gender, Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f047ccf-8ea5-4bf8-a9f5-8386ca0451c6",
   "metadata": {},
   "source": [
    "## Create model and train\n",
    "Gender classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368bef47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset=datasets.ImageFolder('Datasets/Gender2/Training/',transform=transforms.ToTensor())\n",
    "test_dataset=datasets.ImageFolder('Datasets/Gender2/Testing/',transform=transforms.ToTensor())\n",
    "\n",
    "b_size=64\n",
    "train_data=data.DataLoader(train_dataset,batch_size=b_size,shuffle=True)\n",
    "test_data=data.DataLoader(test_dataset,batch_size=b_size,shuffle=False)\n",
    "\n",
    "    \n",
    "model=Gender()\n",
    "\n",
    "criterion=nn.BCELoss(reduction='mean')\n",
    "#optimize=optim.SGD(model.parameters(),lr=0.01,momentum=0.9)\n",
    "optimize=optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for b_i,data_ in enumerate(train_data):\n",
    "        data_,label=data_[0],data_[1]\n",
    "        bashorat=model(data_)\n",
    "        optimize.zero_grad()\n",
    "        label=label.unsqueeze(1)\n",
    "        label=label.float()\n",
    "        xato=criterion(bashorat,label)\n",
    "        xato.backward()\n",
    "        optimize.step()\n",
    "        \n",
    "        if b_i%10==0:\n",
    "            print(f\"Epoch - {epoch} |    {b_i}    | {b_i*b_size}/{len(train_data.dataset)}\\\n",
    "             | Loss - {xato.item()}\")\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    Togri=0\n",
    "    for rasm,label in test_data:\n",
    "        bashorat = model(rasm)\n",
    "        natija = bashorat.detach().numpy().flatten()\n",
    "        natija[natija>0.5]=1.0\n",
    "        natija[natija<=0.5]=0.0\n",
    "        Togri += np.sum(natija==label.detach().numpy())\n",
    "    print(f\"Aniqlik : {Togri/len(test_data.dataset)}, Foizda \\\n",
    "    {100.0*Togri/len(test_data.dataset)}%\")\n",
    "\n",
    "for epoch in range(3):\n",
    "    train(epoch)\n",
    "    test()\n",
    "save(model.state_dict(),'models/gen.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd424022-abd8-44bd-b03b-d5c315ca503d",
   "metadata": {},
   "source": [
    "Age classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1745acbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 | 0  0/8000 | Loss 1.3895798921585083\n",
      "Epoch - 0 | 10  640/8000 | Loss 1.321392297744751\n",
      "Epoch - 0 | 20  1280/8000 | Loss 1.2801265716552734\n",
      "Epoch - 0 | 30  1920/8000 | Loss 1.2711247205734253\n",
      "Epoch - 0 | 40  2560/8000 | Loss 1.110880970954895\n",
      "Epoch - 0 | 50  3200/8000 | Loss 0.9084985256195068\n",
      "Epoch - 0 | 60  3840/8000 | Loss 1.0651421546936035\n",
      "Epoch - 0 | 70  4480/8000 | Loss 1.05500066280365\n",
      "Epoch - 0 | 80  5120/8000 | Loss 0.9240061640739441\n",
      "Epoch - 0 | 90  5760/8000 | Loss 0.9249117374420166\n",
      "Epoch - 0 | 100  6400/8000 | Loss 0.8545721173286438\n",
      "Epoch - 0 | 110  7040/8000 | Loss 1.1797637939453125\n",
      "Epoch - 0 | 120  7680/8000 | Loss 0.824036180973053\n",
      "Aniqlik - 0.6653944253921509 | Foizda - 66.53944396972656%\n",
      "Epoch - 1 | 0  0/8000 | Loss 0.8031066656112671\n",
      "Epoch - 1 | 10  640/8000 | Loss 0.7602176070213318\n",
      "Epoch - 1 | 20  1280/8000 | Loss 0.6089229583740234\n",
      "Epoch - 1 | 30  1920/8000 | Loss 0.6810644268989563\n",
      "Epoch - 1 | 40  2560/8000 | Loss 0.6149344444274902\n",
      "Epoch - 1 | 50  3200/8000 | Loss 0.9051331877708435\n",
      "Epoch - 1 | 60  3840/8000 | Loss 0.6643610000610352\n",
      "Epoch - 1 | 70  4480/8000 | Loss 0.5489500761032104\n",
      "Epoch - 1 | 80  5120/8000 | Loss 0.7852888703346252\n",
      "Epoch - 1 | 90  5760/8000 | Loss 0.7612718939781189\n",
      "Epoch - 1 | 100  6400/8000 | Loss 0.5891004800796509\n",
      "Epoch - 1 | 110  7040/8000 | Loss 0.5919203162193298\n",
      "Epoch - 1 | 120  7680/8000 | Loss 0.574687123298645\n",
      "Aniqlik - 0.7396098375320435 | Foizda - 73.96098327636719%\n",
      "Epoch - 2 | 0  0/8000 | Loss 0.42833778262138367\n",
      "Epoch - 2 | 10  640/8000 | Loss 0.3821185231208801\n",
      "Epoch - 2 | 20  1280/8000 | Loss 0.5935812592506409\n",
      "Epoch - 2 | 30  1920/8000 | Loss 0.49863043427467346\n",
      "Epoch - 2 | 40  2560/8000 | Loss 0.6378947496414185\n",
      "Epoch - 2 | 50  3200/8000 | Loss 0.7340424060821533\n",
      "Epoch - 2 | 60  3840/8000 | Loss 0.3920249044895172\n",
      "Epoch - 2 | 70  4480/8000 | Loss 0.6116472482681274\n",
      "Epoch - 2 | 80  5120/8000 | Loss 0.7550132274627686\n",
      "Epoch - 2 | 90  5760/8000 | Loss 0.5018811225891113\n",
      "Epoch - 2 | 100  6400/8000 | Loss 0.5818942785263062\n",
      "Epoch - 2 | 110  7040/8000 | Loss 0.5498592853546143\n",
      "Epoch - 2 | 120  7680/8000 | Loss 0.46610066294670105\n",
      "Aniqlik - 0.7667514681816101 | Foizda - 76.6751480102539%\n",
      "Epoch - 3 | 0  0/8000 | Loss 0.46420350670814514\n",
      "Epoch - 3 | 10  640/8000 | Loss 0.4515703022480011\n",
      "Epoch - 3 | 20  1280/8000 | Loss 0.47015711665153503\n",
      "Epoch - 3 | 30  1920/8000 | Loss 0.45364657044410706\n",
      "Epoch - 3 | 40  2560/8000 | Loss 0.4657944440841675\n",
      "Epoch - 3 | 50  3200/8000 | Loss 0.42809581756591797\n",
      "Epoch - 3 | 60  3840/8000 | Loss 0.3384501338005066\n",
      "Epoch - 3 | 70  4480/8000 | Loss 0.4105796217918396\n",
      "Epoch - 3 | 80  5120/8000 | Loss 0.44124364852905273\n",
      "Epoch - 3 | 90  5760/8000 | Loss 0.4555041193962097\n",
      "Epoch - 3 | 100  6400/8000 | Loss 0.41000255942344666\n",
      "Epoch - 3 | 110  7040/8000 | Loss 0.5051830410957336\n",
      "Epoch - 3 | 120  7680/8000 | Loss 0.42792606353759766\n",
      "Aniqlik - 0.8672603964805603 | Foizda - 86.72603607177734%\n",
      "Epoch - 4 | 0  0/8000 | Loss 0.4243415892124176\n",
      "Epoch - 4 | 10  640/8000 | Loss 0.34408146142959595\n",
      "Epoch - 4 | 20  1280/8000 | Loss 0.4224667251110077\n",
      "Epoch - 4 | 30  1920/8000 | Loss 0.23768894374370575\n",
      "Epoch - 4 | 40  2560/8000 | Loss 0.3458988666534424\n",
      "Epoch - 4 | 50  3200/8000 | Loss 0.1917075514793396\n",
      "Epoch - 4 | 60  3840/8000 | Loss 0.36010316014289856\n",
      "Epoch - 4 | 70  4480/8000 | Loss 0.431447297334671\n",
      "Epoch - 4 | 80  5120/8000 | Loss 0.4573013186454773\n",
      "Epoch - 4 | 90  5760/8000 | Loss 0.4225006699562073\n",
      "Epoch - 4 | 100  6400/8000 | Loss 0.3592749536037445\n",
      "Epoch - 4 | 110  7040/8000 | Loss 0.4543764293193817\n",
      "Epoch - 4 | 120  7680/8000 | Loss 0.49843907356262207\n",
      "Aniqlik - 0.7586938142776489 | Foizda - 75.86937713623047%\n",
      "Epoch - 5 | 0  0/8000 | Loss 0.20069380104541779\n",
      "Epoch - 5 | 10  640/8000 | Loss 0.2155838906764984\n",
      "Epoch - 5 | 20  1280/8000 | Loss 0.14037539064884186\n",
      "Epoch - 5 | 30  1920/8000 | Loss 0.1741151213645935\n",
      "Epoch - 5 | 40  2560/8000 | Loss 0.2615909278392792\n",
      "Epoch - 5 | 50  3200/8000 | Loss 0.31237468123435974\n",
      "Epoch - 5 | 60  3840/8000 | Loss 0.30260586738586426\n",
      "Epoch - 5 | 70  4480/8000 | Loss 0.37230193614959717\n",
      "Epoch - 5 | 80  5120/8000 | Loss 0.2560008764266968\n",
      "Epoch - 5 | 90  5760/8000 | Loss 0.27474740147590637\n",
      "Epoch - 5 | 100  6400/8000 | Loss 0.2942529320716858\n",
      "Epoch - 5 | 110  7040/8000 | Loss 0.43187928199768066\n",
      "Epoch - 5 | 120  7680/8000 | Loss 0.28352776169776917\n",
      "Aniqlik - 0.8481764197349548 | Foizda - 84.81764221191406%\n",
      "Epoch - 6 | 0  0/8000 | Loss 0.1743021011352539\n",
      "Epoch - 6 | 10  640/8000 | Loss 0.0876416563987732\n",
      "Epoch - 6 | 20  1280/8000 | Loss 0.19544222950935364\n",
      "Epoch - 6 | 30  1920/8000 | Loss 0.15113264322280884\n",
      "Epoch - 6 | 40  2560/8000 | Loss 0.2955170273780823\n",
      "Epoch - 6 | 50  3200/8000 | Loss 0.23342186212539673\n",
      "Epoch - 6 | 60  3840/8000 | Loss 0.22286896407604218\n",
      "Epoch - 6 | 70  4480/8000 | Loss 0.11127430945634842\n",
      "Epoch - 6 | 80  5120/8000 | Loss 0.22935642302036285\n",
      "Epoch - 6 | 90  5760/8000 | Loss 0.22491490840911865\n",
      "Epoch - 6 | 100  6400/8000 | Loss 0.29676738381385803\n",
      "Epoch - 6 | 110  7040/8000 | Loss 0.2005016803741455\n",
      "Epoch - 6 | 120  7680/8000 | Loss 0.21998481452465057\n",
      "Aniqlik - 0.894402027130127 | Foizda - 89.44020080566406%\n",
      "Epoch - 7 | 0  0/8000 | Loss 0.10116710513830185\n",
      "Epoch - 7 | 10  640/8000 | Loss 0.1601911038160324\n",
      "Epoch - 7 | 20  1280/8000 | Loss 0.15812093019485474\n",
      "Epoch - 7 | 30  1920/8000 | Loss 0.04834020137786865\n",
      "Epoch - 7 | 40  2560/8000 | Loss 0.10927090048789978\n",
      "Epoch - 7 | 50  3200/8000 | Loss 0.09325018525123596\n",
      "Epoch - 7 | 60  3840/8000 | Loss 0.1251993030309677\n",
      "Epoch - 7 | 70  4480/8000 | Loss 0.1487589180469513\n",
      "Epoch - 7 | 80  5120/8000 | Loss 0.05747009441256523\n",
      "Epoch - 7 | 90  5760/8000 | Loss 0.07774723321199417\n",
      "Epoch - 7 | 100  6400/8000 | Loss 0.16091486811637878\n",
      "Epoch - 7 | 110  7040/8000 | Loss 0.08900944888591766\n",
      "Epoch - 7 | 120  7680/8000 | Loss 0.2275882065296173\n",
      "Aniqlik - 0.8481764197349548 | Foizda - 84.81764221191406%\n",
      "Epoch - 8 | 0  0/8000 | Loss 0.10624361038208008\n",
      "Epoch - 8 | 10  640/8000 | Loss 0.08810355514287949\n",
      "Epoch - 8 | 20  1280/8000 | Loss 0.03657565638422966\n",
      "Epoch - 8 | 30  1920/8000 | Loss 0.024378396570682526\n",
      "Epoch - 8 | 40  2560/8000 | Loss 0.07683867961168289\n",
      "Epoch - 8 | 50  3200/8000 | Loss 0.07740428298711777\n",
      "Epoch - 8 | 60  3840/8000 | Loss 0.05108846724033356\n",
      "Epoch - 8 | 70  4480/8000 | Loss 0.08199089020490646\n",
      "Epoch - 8 | 80  5120/8000 | Loss 0.14918135106563568\n",
      "Epoch - 8 | 90  5760/8000 | Loss 0.021496638655662537\n",
      "Epoch - 8 | 100  6400/8000 | Loss 0.06682287156581879\n",
      "Epoch - 8 | 110  7040/8000 | Loss 0.03151160851120949\n",
      "Epoch - 8 | 120  7680/8000 | Loss 0.08284750580787659\n",
      "Aniqlik - 0.894402027130127 | Foizda - 89.44020080566406%\n",
      "Epoch - 9 | 0  0/8000 | Loss 0.0666951835155487\n",
      "Epoch - 9 | 10  640/8000 | Loss 0.026660071685910225\n",
      "Epoch - 9 | 20  1280/8000 | Loss 0.03375061973929405\n",
      "Epoch - 9 | 30  1920/8000 | Loss 0.06116107106208801\n",
      "Epoch - 9 | 40  2560/8000 | Loss 0.03991926088929176\n",
      "Epoch - 9 | 50  3200/8000 | Loss 0.06285075098276138\n",
      "Epoch - 9 | 60  3840/8000 | Loss 0.032131001353263855\n",
      "Epoch - 9 | 70  4480/8000 | Loss 0.038371533155441284\n",
      "Epoch - 9 | 80  5120/8000 | Loss 0.03880767524242401\n",
      "Epoch - 9 | 90  5760/8000 | Loss 0.12999191880226135\n",
      "Epoch - 9 | 100  6400/8000 | Loss 0.08471379429101944\n",
      "Epoch - 9 | 110  7040/8000 | Loss 0.07388515770435333\n",
      "Epoch - 9 | 120  7680/8000 | Loss 0.03670060634613037\n",
      "Aniqlik - 0.7938931584358215 | Foizda - 79.38931274414062%\n",
      "Epoch - 10 | 0  0/8000 | Loss 0.0570717416703701\n",
      "Epoch - 10 | 10  640/8000 | Loss 0.024317875504493713\n",
      "Epoch - 10 | 20  1280/8000 | Loss 0.06594689190387726\n",
      "Epoch - 10 | 30  1920/8000 | Loss 0.03686896711587906\n",
      "Epoch - 10 | 40  2560/8000 | Loss 0.023077424615621567\n",
      "Epoch - 10 | 50  3200/8000 | Loss 0.10207672417163849\n",
      "Epoch - 10 | 60  3840/8000 | Loss 0.030585603788495064\n",
      "Epoch - 10 | 70  4480/8000 | Loss 0.0659090206027031\n",
      "Epoch - 10 | 80  5120/8000 | Loss 0.10463564842939377\n",
      "Epoch - 10 | 90  5760/8000 | Loss 0.0566401444375515\n",
      "Epoch - 10 | 100  6400/8000 | Loss 0.12468694895505905\n",
      "Epoch - 10 | 110  7040/8000 | Loss 0.02282087691128254\n",
      "Epoch - 10 | 120  7680/8000 | Loss 0.14153191447257996\n",
      "Aniqlik - 0.8553858995437622 | Foizda - 85.53858947753906%\n",
      "Epoch - 11 | 0  0/8000 | Loss 0.09946771711111069\n",
      "Epoch - 11 | 10  640/8000 | Loss 0.028403867036104202\n",
      "Epoch - 11 | 20  1280/8000 | Loss 0.0372576043009758\n",
      "Epoch - 11 | 30  1920/8000 | Loss 0.07844405621290207\n",
      "Epoch - 11 | 40  2560/8000 | Loss 0.04113868996500969\n",
      "Epoch - 11 | 50  3200/8000 | Loss 0.023141659796237946\n",
      "Epoch - 11 | 60  3840/8000 | Loss 0.13452787697315216\n",
      "Epoch - 11 | 70  4480/8000 | Loss 0.04836954548954964\n",
      "Epoch - 11 | 80  5120/8000 | Loss 0.09562376886606216\n",
      "Epoch - 11 | 90  5760/8000 | Loss 0.05290588364005089\n",
      "Epoch - 11 | 100  6400/8000 | Loss 0.11665256321430206\n",
      "Epoch - 11 | 110  7040/8000 | Loss 0.027774628251791\n",
      "Epoch - 11 | 120  7680/8000 | Loss 0.08044880628585815\n",
      "Aniqlik - 0.7938931584358215 | Foizda - 79.38931274414062%\n",
      "Epoch - 12 | 0  0/8000 | Loss 0.0673815980553627\n",
      "Epoch - 12 | 10  640/8000 | Loss 0.0163462795317173\n",
      "Epoch - 12 | 20  1280/8000 | Loss 0.022691635414958\n",
      "Epoch - 12 | 30  1920/8000 | Loss 0.031451478600502014\n",
      "Epoch - 12 | 40  2560/8000 | Loss 0.0249469131231308\n",
      "Epoch - 12 | 50  3200/8000 | Loss 0.00918969139456749\n",
      "Epoch - 12 | 60  3840/8000 | Loss 0.014492923393845558\n",
      "Epoch - 12 | 70  4480/8000 | Loss 0.027627525851130486\n",
      "Epoch - 12 | 80  5120/8000 | Loss 0.07622464746236801\n",
      "Epoch - 12 | 90  5760/8000 | Loss 0.004887592047452927\n",
      "Epoch - 12 | 100  6400/8000 | Loss 0.06193861365318298\n",
      "Epoch - 12 | 110  7040/8000 | Loss 0.0058707972057163715\n",
      "Epoch - 12 | 120  7680/8000 | Loss 0.030568735674023628\n",
      "Aniqlik - 0.8401187658309937 | Foizda - 84.01187133789062%\n",
      "Epoch - 13 | 0  0/8000 | Loss 0.008696179836988449\n",
      "Epoch - 13 | 10  640/8000 | Loss 0.013983170501887798\n",
      "Epoch - 13 | 20  1280/8000 | Loss 0.007997705601155758\n",
      "Epoch - 13 | 30  1920/8000 | Loss 0.01952543295919895\n",
      "Epoch - 13 | 40  2560/8000 | Loss 0.001619261340238154\n",
      "Epoch - 13 | 50  3200/8000 | Loss 0.010266600176692009\n",
      "Epoch - 13 | 60  3840/8000 | Loss 0.028872065246105194\n",
      "Epoch - 13 | 70  4480/8000 | Loss 0.0036926078610122204\n",
      "Epoch - 13 | 80  5120/8000 | Loss 0.015900082886219025\n",
      "Epoch - 13 | 90  5760/8000 | Loss 0.015515092760324478\n",
      "Epoch - 13 | 100  6400/8000 | Loss 0.0036877854727208614\n",
      "Epoch - 13 | 110  7040/8000 | Loss 0.009898364543914795\n",
      "Epoch - 13 | 120  7680/8000 | Loss 0.00917745754122734\n",
      "Aniqlik - 0.8401187658309937 | Foizda - 84.01187133789062%\n",
      "Epoch - 14 | 0  0/8000 | Loss 0.0011742268688976765\n",
      "Epoch - 14 | 10  640/8000 | Loss 0.006106265354901552\n",
      "Epoch - 14 | 20  1280/8000 | Loss 0.002991854678839445\n",
      "Epoch - 14 | 30  1920/8000 | Loss 0.0003985821094829589\n",
      "Epoch - 14 | 40  2560/8000 | Loss 0.004334819968789816\n",
      "Epoch - 14 | 50  3200/8000 | Loss 0.0015408653998747468\n",
      "Epoch - 14 | 60  3840/8000 | Loss 0.005410256329923868\n",
      "Epoch - 14 | 70  4480/8000 | Loss 0.003358021378517151\n",
      "Epoch - 14 | 80  5120/8000 | Loss 0.0024970294907689095\n",
      "Epoch - 14 | 90  5760/8000 | Loss 0.003705058479681611\n",
      "Epoch - 14 | 100  6400/8000 | Loss 0.0005887463921681046\n",
      "Epoch - 14 | 110  7040/8000 | Loss 0.001890217186883092\n",
      "Epoch - 14 | 120  7680/8000 | Loss 0.0011528467293828726\n",
      "Aniqlik - 0.8672603964805603 | Foizda - 86.72603607177734%\n"
     ]
    }
   ],
   "source": [
    "b_size=64\n",
    "\n",
    "train_dataset=datasets.ImageFolder('Datasets/Age2/train',transform=transforms.ToTensor())\n",
    "test_dataset=datasets.ImageFolder('Datasets/Age2/test',transform=transforms.ToTensor())\n",
    "\n",
    "train_data=data.DataLoader(train_dataset,batch_size=b_size,shuffle=True)\n",
    "test_data=data.DataLoader(test_dataset,batch_size=b_size,shuffle=False)\n",
    "    \n",
    "model=Age()\n",
    "\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimize=optim.SGD(model.parameters(),lr=0.01,momentum=0.9)\n",
    "#optimize=optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for b_i,malumot in enumerate(train_data):\n",
    "        mal,label=malumot[0],malumot[1]\n",
    "        optimize.zero_grad()\n",
    "        bashorat=model(mal)\n",
    "        xato=criterion(bashorat,label)\n",
    "        xato.backward()\n",
    "        optimize.step()\n",
    "        if b_i%10==0:\n",
    "            print(f\"Epoch - {epoch} | {b_i}  {b_i*len(mal)}/{len(train_data.dataset)} | Loss {xato.item()}\")\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    togri=0\n",
    "    for mal,label in test_data:\n",
    "        bashorat=model(mal)\n",
    "        natija=bashorat.data.argmax(1,keepdim=True)[1]\n",
    "        togri+=natija.eq(label.data).cpu().sum()\n",
    "    print(f\"Aniqlik - {togri/len(test_data.dataset)} | Foizda - {100*togri/len(test_data.dataset)}%\")\n",
    "    \n",
    "for epoch in range(15):\n",
    "    train(epoch)\n",
    "    test()\n",
    "save(model.state_dict(),'models/age.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
